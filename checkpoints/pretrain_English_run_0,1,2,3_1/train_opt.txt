----------------- Options ---------------
                   A_type: wav2vec2-base-960h-UTT        	[default: None]
                   L_type: roberta-base-4-FRA            	[default: None]
         Transformer_head: 2                             
       Transformer_layers: 1                             
                   V_type: temonet_UTT                   	[default: None]
                 ablation: normal                        
             activate_fun: relu                          
               activation: relu                          
        attention_dropout: 0.0                           
           attention_head: 1                             
               batch_size: 32                            	[default: 128]
                best_cvNo: 1                             
                    beta1: 0.5                           
                       bn: False                         
                ce_weight: 1.0                           
          checkpoints_dir: ./checkpoints                 
                     clip: 1.0                           
               cls_layers: 128,64                        	[default: 128,128]
               cls_weight: 1                             
           continue_train: False                         
              corpus_name: MEIJU_English                 	[default: IEMOCAP]
           cuda_benchmark: False                         
                     cvNo: 1                             	[default: None]
                data_path: None                          
             dataset_mode: multimodal                    
              diff_weight: 0.15                          
                drop_last: False                         
                  dropout: 0.5                           
             dropout_rate: 0.2                           	[default: 0.3]
            embd_method_a: maxpool                       
            embd_method_v: maxpool                       
              embd_size_a: 32                            	[default: 128]
              embd_size_l: 128                           
              embd_size_v: 128                           
           embedding_size: 300                           
           emo_output_dim: 7                             	[default: None]
                    epoch: latest                        
              epoch_count: 1                             
          eval_batch_size: 10                            
             focal_weight: 1.0                           
                  gpu_ids: 0                             	[default: 3]
                 has_test: False                         
              hidden_size: 128                           
                init_gain: 0.012                         
                init_type: kaiming                       
              input_dim_a: 768                           	[default: 130]
              input_dim_l: 768                           	[default: 1024]
              input_dim_v: 342                           	[default: 384]
           int_output_dim: 8                             	[default: None]
                  isTrain: True                          	[default: None]
            learning_rate: 0.0001                        
                  log_dir: ./logs                        
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                     mode: train                         
                    model: our                           	[default: mmin]
                  n_epoch: 500                           
                     name: pretrain_English_run_0,1,2,3_1	[default: None]
                    niter: 20                            
              niter_decay: 80                            
                     norm: instance                      
              norm_method: None                          
              num_classes: 10                            
              num_threads: 8                             	[default: 0]
                optimizer: Adam                          
                 patience: 6                             
                    phase: train                         
          pretrained_path: None                          
               print_freq: 100                           
              random_seed: 336                           
             recon_weight: 0.025                         
      reverse_grad_weight: 1.0                           
                  rnncell: lstm                          
                  run_idx: None                          
                     runs: 5                             
          save_epoch_freq: 1                             
           serial_batches: False                         
               shared_dir: ./shared                      
               sim_weight: 0.025                         
                sp_weight: 0.0                           
                   suffix:                               
              temperature: 0.007                         
                    track: 2                             	[default: 1]
                  use_ICL: True                          	[default: None]
                 use_bert: True                          
              use_cmd_sim: True                          
                  verbose: False                         
             weight_decay: 1e-05                         	[default: 0.0]
----------------- End -------------------
